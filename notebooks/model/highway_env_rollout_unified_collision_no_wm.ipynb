{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/u/shuhan/projects/vla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.vlas.cont_obs_token_action_cot_unified_token_collision import ContObsTokenActionCOTVLAUnifiedTokenCollision\n",
    "from src.auto_labeling.highway_env.lane_change import LaneChangeTaskSpecCollision\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "llm_model = 'HuggingFaceTB/SmolLM2-135M-Instruct'\n",
    "\n",
    "llm_backbone = AutoModelForCausalLM.from_pretrained(llm_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weight = {\"action\": 1.0, \"obs\": 0.0, 'reconst': 1.0, \"cot\": 1.0, \"separator\": 1.0, \"rollout_stop\": 1.0, \"wm\": 1.0}\n",
    "cot_mode = 'start'\n",
    "\n",
    "cot_cfg = {'lanes_count': 5, 'max_hop': 4, 'cot_index_mode': 'both', 'action_sample_mode': 'future', 'safe_reflect_rate': 0.3, 'collide_reflect_rate': 0.8, 'collide_rewind_rate': 0.8}\n",
    "\n",
    "if llm_model == 'gpt2':\n",
    "  hidden_dim = 768\n",
    "elif llm_model == 'HuggingFaceTB/SmolLM2-135M-Instruct':\n",
    "  hidden_dim = 576\n",
    "else:\n",
    "  raise ValueError(f'Unknown LLM model: {llm_model}')\n",
    "\n",
    "obs_dim = 25\n",
    "num_actions = 5\n",
    "mlp_layers = 2\n",
    "\n",
    "task_spec_func = LaneChangeTaskSpecCollision\n",
    "\n",
    "# model = ContObsTokenActionCOTVLAUnifiedTokenCollision(llm_backbone, tokenizer, task_spec_func, obs_dim, num_actions, hidden_dim, mlp_layers, loss_weight, cot_mode, cot_cfg, max_obs_len=50, use_wm=True)\n",
    "\n",
    "model = ContObsTokenActionCOTVLAUnifiedTokenCollision(llm_backbone, tokenizer, task_spec_func, obs_dim, num_actions, hidden_dim, mlp_layers, loss_weight, cot_mode, cot_cfg, max_obs_len=50, use_wm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49216"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.llm_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# ckpt = '~/results/vla/quick_run_cot_unified_collision/with_wm_cr_0.8_re_0.2_sr_0.2/lightning_logs/version_0/checkpoints/test_model.ckpt'\n",
    "ckpt = '~/results/vla/quick_run_cot_unified_collision/no_wm_cr_0.8_re_0.8_sr_0.2/lightning_logs/version_2/checkpoints/test_model.ckpt'\n",
    "ckpt = os.path.expanduser(ckpt)\n",
    "\n",
    "lg_ckpt = torch.load(ckpt, map_location='cpu', weights_only=True)['state_dict']\n",
    "ori_ckpt = {}\n",
    "for k, v in lg_ckpt.items():\n",
    "    if k.startswith('vla.'):\n",
    "        ori_ckpt[k[4:]] = v\n",
    "\n",
    "model.load_state_dict(ori_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "sys.path.append('/u/shuhan/projects/vla')\n",
    "\n",
    "from src.environments.highway_env.dataset import HighwayCollisionDataset, collate_fn_collision\n",
    "\n",
    "dataset = HighwayCollisionDataset(data_dir='/storage/Datasets/highway_env/highway_fast_v0_dqn_meta_action_5_lanes/rollouts_train_collision', overfit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn_collision)\n",
    "\n",
    "for batch in dataloader:\n",
    "  batch_data = batch\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "loss_dict, batch_input_embeds, batch_label_ids, batch_input_ids, llm_output = model(batch_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'separator': tensor(0.0958, grad_fn=<MeanBackward0>),\n",
       " 'rollout_stop': tensor(1.1921e-07, grad_fn=<MeanBackward0>),\n",
       " 'action': tensor(0.1952, grad_fn=<MeanBackward0>),\n",
       " 'cot': tensor(3.2981e-06, grad_fn=<MeanBackward0>),\n",
       " 'reconst': tensor(0.0001, grad_fn=<DivBackward0>),\n",
       " 'total': tensor(0.2911, grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "goal_spec_dataset_path = '/u/shuhan/projects/vla/data/highway_env/lane_change_goal_spec_data.pkl'\n",
    "with open(goal_spec_dataset_path, 'rb') as f:\n",
    "  goal_spec_dataset = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import gymnasium\n",
    "import highway_env\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from difflib import SequenceMatcher\n",
    "import copy\n",
    "\n",
    "from transformers.cache_utils import DynamicCache\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def get_ego_lane_id(curr_obs):\n",
    "  lane_cnt = 5\n",
    "  lane_width = 1.0 / lane_cnt\n",
    "  abs_y = curr_obs[..., 2].copy()\n",
    "  abs_y[1:] += abs_y[:1]\n",
    "  abs_y += lane_width / 2\n",
    "  lane_ids = (abs_y / lane_width).astype(int)\n",
    "  ego_lane_id = lane_ids[0]\n",
    "  return ego_lane_id\n",
    "\n",
    "def compute_path_score(goal_path: list[int], ego_lane_ids: list[int]):\n",
    "  # exact match\n",
    "  exact_match_count = sum(1 for g, e in zip(goal_path, ego_lane_ids) if g == e)\n",
    "  exact_match_score = exact_match_count / len(goal_path)\n",
    "\n",
    "  # subset coverage\n",
    "  sequence_matcher = SequenceMatcher(None, goal_path, ego_lane_ids)\n",
    "  longest_match_length = sequence_matcher.find_longest_match(0, len(goal_path), 0, len(ego_lane_ids)).size\n",
    "  subset_coverage = longest_match_length / len(goal_path)\n",
    "\n",
    "  return exact_match_score, subset_coverage\n",
    "\n",
    "def get_wm_obs_from_env(env, action_id):\n",
    "  '''\n",
    "  Get the WM observation from the environment. The environment itself is not affected.\n",
    "  '''\n",
    "\n",
    "  start_env_state = copy.deepcopy(env.__dict__)\n",
    "\n",
    "  wm_env = gymnasium.make(\"highway-fast-v0\", render_mode='rgb_array', config={\"lanes_count\": 5})\n",
    "  _, _ = wm_env.reset()\n",
    "  wm_env.__dict__.update(start_env_state) \n",
    "\n",
    "  wm_obs, _, has_collision, _, _ = wm_env.step(action_id)\n",
    "\n",
    "  if has_collision:\n",
    "    print('wm collision!')\n",
    "  else:\n",
    "    print('wm safe!')\n",
    "  return wm_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gymnasium.make(\"highway-fast-v0\", render_mode='rgb_array', config={\"lanes_count\": 5})\n",
    "curr_obs, _ = env.reset()\n",
    "ego_lane_id = get_ego_lane_id(curr_obs)\n",
    "\n",
    "sampled_path_info = random.choice(goal_spec_dataset[ego_lane_id])\n",
    "\n",
    "goal_spec = sampled_path_info['goal_spec']\n",
    "hop_lane_ids = sampled_path_info['hop_lane_ids']\n",
    "\n",
    "start_id = hop_lane_ids[0]\n",
    "goal_id = hop_lane_ids[-1]\n",
    "\n",
    "curr_obs = torch.tensor(curr_obs, dtype=torch.float32)\n",
    "\n",
    "max_rollout_length = 30\n",
    "\n",
    "ego_lane_ids = [start_id]\n",
    "actions = []\n",
    "model_failed = False\n",
    "rollout_collision = False\n",
    "\n",
    "past_input_str = goal_spec\n",
    "past_key_value = DynamicCache()\n",
    "past_input_embeds = model.llm_backbone.get_input_embeddings()(model.llm_tokenizer(past_input_str, return_tensors='pt').input_ids.to(curr_obs.device))\n",
    "\n",
    "generate_cfg = {'max_new_tokens': 100, 'do_sample': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple of tuples. This is deprecated and will be removed in v4.47. Please convert your cache or use an appropriate `Cache` class (https://huggingface.co/docs/transformers/kv_cache#legacy-cache-format)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOO><Obs_0><EOO><BOA><Act_3><EOA>\n"
     ]
    }
   ],
   "source": [
    "init_act_str, init_act_embeddings = model.init_action_inference(past_input_embeds, past_input_str, curr_obs, generate_cfg)\n",
    "\n",
    "print(init_act_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_act_idx = init_act_str.index('<Act_')\n",
    "init_act_id = int(init_act_str[init_act_idx+5:init_act_idx+6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_act_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_input_str = past_input_str + init_act_str\n",
    "past_input_embeds = torch.cat([past_input_embeds, init_act_embeddings], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOT>\n"
     ]
    }
   ],
   "source": [
    "use_wm = False\n",
    "\n",
    "# cot_mode = 'pred'\n",
    "cot_mode = 'always'\n",
    "\n",
    "cot_token_str, cot_token_embeddings = model.cot_start_inference(past_input_embeds, past_input_str, cot_mode, use_wm)\n",
    "\n",
    "print(cot_token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal is to reach Lane 4. Need to go through path Lane 0 -> Lane 1 -> Lane 2 -> Lane 3 -> Lane 4.<BOO><Obs_0><EOO><BOA><Act_3><EOA><BOT>\n"
     ]
    }
   ],
   "source": [
    "if len(cot_token_str) > 0:\n",
    "  past_input_str = past_input_str + cot_token_str\n",
    "  past_input_embeds = torch.cat([past_input_embeds, cot_token_embeddings], dim=1)\n",
    "\n",
    "print(past_input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe<EOT><COMMIT>\n"
     ]
    }
   ],
   "source": [
    "commit_str, commit_embeddings = model.cot_commit_inference(past_input_embeds, past_input_str, generate_cfg)\n",
    "print(commit_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rollout_one_episode(model, goal_spec_dataset, cot_inference_mode: str):\n",
    "    env = gymnasium.make(\"highway-fast-v0\", render_mode='rgb_array', config={\"lanes_count\": 5})\n",
    "    curr_obs, _ = env.reset()\n",
    "    ego_lane_id = get_ego_lane_id(curr_obs)\n",
    "\n",
    "    sampled_path_info = random.choice(goal_spec_dataset[ego_lane_id])\n",
    "\n",
    "    goal_spec = sampled_path_info['goal_spec']\n",
    "    hop_lane_ids = sampled_path_info['hop_lane_ids']\n",
    "\n",
    "    start_id = hop_lane_ids[0]\n",
    "    goal_id = hop_lane_ids[-1]\n",
    "\n",
    "    curr_obs = torch.tensor(curr_obs, dtype=torch.float32)\n",
    "\n",
    "    max_rollout_length = 30\n",
    "\n",
    "    ego_lane_ids = [start_id]\n",
    "    actions = []\n",
    "    model_failed = False\n",
    "    rollout_collision = False\n",
    "\n",
    "    past_input_str = goal_spec\n",
    "    past_key_value = DynamicCache()\n",
    "    past_input_embeds = model.llm_backbone.get_input_embeddings()(model.llm_tokenizer(past_input_str, return_tensors='pt').input_ids.to(curr_obs.device))\n",
    "\n",
    "    generate_cfg = {'max_new_tokens': 100, 'do_sample': False}\n",
    "\n",
    "    # print(past_input_str)\n",
    "\n",
    "    for _ in range(max_rollout_length):\n",
    "        update_str, update_embeddings = model.inference_step(past_input_embeds, past_input_str, past_key_value, curr_obs, cot_inference_mode, generate_cfg)\n",
    "        # print(update_str)\n",
    "\n",
    "        past_input_str = past_input_str + update_str\n",
    "        \n",
    "        if past_input_embeds is None:\n",
    "            past_input_embeds = update_embeddings\n",
    "        else:\n",
    "            past_input_embeds = torch.cat([past_input_embeds, update_embeddings], dim=1)\n",
    "\n",
    "        if '<EndOfRollout>' in update_str:\n",
    "            print('model called end of rollout!')\n",
    "            break\n",
    "\n",
    "        if '<Act_' not in update_str:\n",
    "            print('no action token in the update string!')\n",
    "            model_failed = True\n",
    "            break\n",
    "\n",
    "        act_index = update_str.index('<Act_')\n",
    "        act_id = int(update_str[act_index+5:act_index+6])\n",
    "\n",
    "\n",
    "        obs, reward, has_collision, truncated, info = env.step(act_id)\n",
    "        ego_lane_id = get_ego_lane_id(obs)\n",
    "        \n",
    "        # print(f'step: {len(actions)}, action: {act_id}, ego_lane_id: {ego_lane_id}')\n",
    "\n",
    "        actions.append(act_id)\n",
    "        ego_lane_ids.append(ego_lane_id)\n",
    "\n",
    "        curr_obs = torch.tensor(obs, dtype=torch.float32)\n",
    "\n",
    "        if truncated:\n",
    "            print('rollout finished!')\n",
    "            break\n",
    "\n",
    "        if has_collision:\n",
    "            rollout_collision = True\n",
    "            print('rollout collision!')\n",
    "            break\n",
    "\n",
    "    # remove repeating lane ids\n",
    "    ego_lane_ids = [ego_lane_ids[0]] + [ego_lane_ids[i] for i in range(1, len(ego_lane_ids)) if ego_lane_ids[i] != ego_lane_ids[i-1]]\n",
    "\n",
    "    token_count = past_input_embeds.shape[1]\n",
    "    action_count = len(actions)\n",
    "    reached_goal = (ego_lane_ids[-1] == goal_id) and not (model_failed or rollout_collision) and len(ego_lane_ids) == len(hop_lane_ids)\n",
    "    exact_match_score, subset_coverage = compute_path_score(hop_lane_ids, ego_lane_ids)\n",
    "\n",
    "    exceeded_length = max(0, len(ego_lane_ids) - len(hop_lane_ids))\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    scores = {'token_count': token_count, 'action_count': action_count, 'exact_match_score': exact_match_score, 'subset_coverage': subset_coverage, 'model_failed': model_failed, 'rollout_collision': rollout_collision, 'reached_goal': reached_goal, 'exceeded_length': exceeded_length}\n",
    "\n",
    "    return scores, past_input_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "log_dir = 'logs'\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollout collision!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:07<00:00,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollout collision!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import logging\n",
    "import os\n",
    "\n",
    "\n",
    "# cot_inference_mode = 'pred'\n",
    "# cot_inference_mode = 'start'\n",
    "cot_inference_mode = 'never'\n",
    "exp_name = f'{model_name}_{cot_inference_mode}'\n",
    "\n",
    "save_dir = '/u/shuhan/projects/vla/data/highway_env/rollout_experiment'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=os.path.join(save_dir, f'{exp_name}.log'),\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(message)s'\n",
    ")\n",
    "\n",
    "all_scores = {'token_count': [], 'action_count': [], 'exact_match_score': [], 'subset_coverage': [], 'model_failed': [], 'rollout_collision': [], 'reached_goal': [], 'exceeded_length': []}\n",
    "all_past_input_str = []\n",
    "\n",
    "rollout_count = 2\n",
    "\n",
    "\n",
    "for rollout_idx in tqdm.tqdm(range(rollout_count)):\n",
    "    scores, past_input_str = rollout_one_episode(model, goal_spec_dataset, cot_inference_mode)\n",
    "    for k, v in scores.items():\n",
    "        all_scores[k].append(v)\n",
    "    all_past_input_str.append(past_input_str)\n",
    "\n",
    "    logging.info(f'rollout {rollout_idx} done')\n",
    "\n",
    "    for k, v in all_scores.items():\n",
    "        logging.info(f'\\t {k}: {np.mean(v)}')\n",
    "\n",
    "logging.info('final results:')\n",
    "for k, v in all_scores.items():\n",
    "    logging.info(f'\\t {k}: {np.mean(v)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vla_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
