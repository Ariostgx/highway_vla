{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/u/shuhan/projects/vla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.vlas.cont_obs_token_action_cot_unified_token_collision import ContObsTokenActionCOTVLAUnifiedTokenCollision\n",
    "from src.auto_labeling.highway_env.lane_change import LaneChangeTaskSpecCollision\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "llm_model = 'HuggingFaceTB/SmolLM2-135M-Instruct'\n",
    "\n",
    "llm_backbone = AutoModelForCausalLM.from_pretrained(llm_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weight = {\"action\": 1.0, \"obs\": 0.0, 'reconst': 1.0, \"cot\": 1.0, \"separator\": 1.0, \"rollout_stop\": 1.0, \"wm\": 1.0}\n",
    "cot_mode = 'start'\n",
    "\n",
    "cot_cfg = {'lanes_count': 5, 'max_hop': 4, 'cot_index_mode': 'both', 'action_sample_mode': 'future', 'safe_reflect_rate': 0.3, 'collide_reflect_rate': 0.8, 'collide_rewind_rate': 0.8}\n",
    "\n",
    "if llm_model == 'gpt2':\n",
    "  hidden_dim = 768\n",
    "elif llm_model == 'HuggingFaceTB/SmolLM2-135M-Instruct':\n",
    "  hidden_dim = 576\n",
    "else:\n",
    "  raise ValueError(f'Unknown LLM model: {llm_model}')\n",
    "\n",
    "obs_dim = 25\n",
    "num_actions = 5\n",
    "mlp_layers = 2\n",
    "\n",
    "task_spec_func = LaneChangeTaskSpecCollision\n",
    "\n",
    "# use_wm = False\n",
    "use_wm = True\n",
    "\n",
    "model = ContObsTokenActionCOTVLAUnifiedTokenCollision(llm_backbone, tokenizer, task_spec_func, obs_dim, num_actions, hidden_dim, mlp_layers, loss_weight, cot_mode, cot_cfg, max_obs_len=50, use_wm=use_wm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the avalibale GPU id and create a device\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "if use_wm:\n",
    "  ckpt = '~/results/vla/quick_run_cot_unified_collision/with_wm_cr_0.8_re_0.2_sr_0.2/lightning_logs/version_0/checkpoints/test_model.ckpt'\n",
    "else:\n",
    "  ckpt = '~/results/vla/quick_run_cot_unified_collision/no_wm_cr_0.8_re_0.8_sr_0.2/lightning_logs/version_2/checkpoints/test_model.ckpt'\n",
    "\n",
    "ckpt = os.path.expanduser(ckpt)\n",
    "\n",
    "lg_ckpt = torch.load(ckpt, map_location='cpu', weights_only=True)['state_dict']\n",
    "ori_ckpt = {}\n",
    "for k, v in lg_ckpt.items():\n",
    "    if k.startswith('vla.'):\n",
    "        ori_ckpt[k[4:]] = v\n",
    "\n",
    "model.load_state_dict(ori_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "sys.path.append('/u/shuhan/projects/vla')\n",
    "\n",
    "from src.environments.highway_env.dataset import HighwayCollisionDataset, collate_fn_collision\n",
    "\n",
    "dataset = HighwayCollisionDataset(data_dir='/storage/Datasets/highway_env/highway_fast_v0_dqn_meta_action_5_lanes/rollouts_train_collision', overfit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn_collision)\n",
    "\n",
    "for batch in dataloader:\n",
    "  batch_data = batch\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_dict, batch_input_embeds, batch_label_ids, batch_input_ids, llm_output = model(batch_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "goal_spec_dataset_path = '/u/shuhan/projects/vla/data/highway_env/lane_change_goal_spec_data.pkl'\n",
    "with open(goal_spec_dataset_path, 'rb') as f:\n",
    "  goal_spec_dataset = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import gymnasium\n",
    "import highway_env\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from difflib import SequenceMatcher\n",
    "import copy\n",
    "\n",
    "from transformers.cache_utils import DynamicCache\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def get_ego_lane_id(curr_obs):\n",
    "  lane_cnt = 5\n",
    "  lane_width = 1.0 / lane_cnt\n",
    "  abs_y = curr_obs[..., 2].copy()\n",
    "  abs_y[1:] += abs_y[:1]\n",
    "  abs_y += lane_width / 2\n",
    "  lane_ids = (abs_y / lane_width).astype(int)\n",
    "  ego_lane_id = lane_ids[0]\n",
    "  return ego_lane_id\n",
    "\n",
    "def compute_path_score(goal_path: list[int], ego_lane_ids: list[int]):\n",
    "  # exact match\n",
    "  exact_match_count = sum(1 for g, e in zip(goal_path, ego_lane_ids) if g == e)\n",
    "  exact_match_score = exact_match_count / len(goal_path)\n",
    "\n",
    "  # subset coverage\n",
    "  sequence_matcher = SequenceMatcher(None, goal_path, ego_lane_ids)\n",
    "  longest_match_length = sequence_matcher.find_longest_match(0, len(goal_path), 0, len(ego_lane_ids)).size\n",
    "  subset_coverage = longest_match_length / len(goal_path)\n",
    "\n",
    "  return exact_match_score, subset_coverage\n",
    "\n",
    "def get_wm_obs_from_env(env, action_id):\n",
    "  '''\n",
    "  Get the WM observation from the environment. The environment itself is not affected.\n",
    "  '''\n",
    "\n",
    "  start_env_state = copy.deepcopy(env.__dict__)\n",
    "\n",
    "  wm_env = gymnasium.make(\"highway-fast-v0\", render_mode='rgb_array', config={\"lanes_count\": 5})\n",
    "  _, _ = wm_env.reset()\n",
    "  wm_env.__dict__.update(start_env_state) \n",
    "\n",
    "  wm_obs, _, has_collision, _, _ = wm_env.step(action_id)\n",
    "\n",
    "  if has_collision:\n",
    "    print('wm collision!')\n",
    "  else:\n",
    "    print('wm safe!')\n",
    "  return wm_obs, has_collision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal is to reach Lane 3. Need to go through path Lane 1 -> Lane 0 -> Lane 1 -> Lane 2 -> Lane 3.\n",
      "\tinit_act_str: <BOO><Obs_0><EOO><BOA><Act_3><EOA>\n",
      "\tcot_token_str: <COMMIT>\n",
      "step: 0, action: 3, ego_lane_id: 1\n",
      "\tinit_act_str: <BOO><Obs_1><EOO><BOA><Act_3><EOA>\n",
      "\tcot_token_str: <COMMIT>\n",
      "step: 1, action: 3, ego_lane_id: 1\n",
      "\tinit_act_str: <BOO><Obs_2><EOO><BOA><Act_1><EOA>\n",
      "\tcot_token_str: <BWM>\n",
      "\tcommit_str: <BOT>Safe<EOT><COMMIT>\n",
      "wm safe!\n",
      "\tsafe, continue to use the initial action!\n",
      "step: 2, action: 1, ego_lane_id: 1\n",
      "\tinit_act_str: <BOO><Obs_3><EOO><BOA><Act_1><EOA>\n",
      "\tcot_token_str: <BWM>\n",
      "\tcommit_str: <BOT>Safe<EOT><COMMIT>\n",
      "wm safe!\n",
      "\tsafe, continue to use the initial action!\n",
      "step: 3, action: 1, ego_lane_id: 1\n",
      "\tinit_act_str: <BOO><Obs_4><EOO><BOA><Act_1><EOA>\n",
      "\tcot_token_str: <COMMIT>\n",
      "step: 4, action: 1, ego_lane_id: 1\n",
      "\tinit_act_str: <BOO><Obs_5><EOO><BOA><Act_2><EOA>\n",
      "\tcot_token_str: <COMMIT>\n",
      "step: 5, action: 2, ego_lane_id: 2\n",
      "\tinit_act_str: <BOO><Obs_6><EOO><BOA><Act_1><EOA>\n",
      "\tcot_token_str: <BWM>\n",
      "\tcommit_str: <BOT>Safe<EOT><COMMIT>\n",
      "wm safe!\n",
      "\tsafe, continue to use the initial action!\n",
      "step: 6, action: 1, ego_lane_id: 2\n",
      "\tinit_act_str: <BOO><Obs_7><EOO><BOA><Act_3><EOA>\n",
      "\tcot_token_str: <COMMIT>\n",
      "step: 7, action: 3, ego_lane_id: 2\n",
      "\tinit_act_str: <BOO><Obs_8><EOO><BOA><Act_2><EOA>\n",
      "\tcot_token_str: <COMMIT>\n",
      "step: 8, action: 2, ego_lane_id: 3\n",
      "\tinit_act_str: <BOO><Obs_9><EOO><BOA><Act_2><EOA>\n",
      "\tcot_token_str: <COMMIT>\n",
      "step: 9, action: 2, ego_lane_id: 4\n",
      "\tinit_act_str: <BOO><Obs_10><EOO><EndOfRollout><Act_0><EOA>\n",
      "\tmodel called end of rollout!\n"
     ]
    }
   ],
   "source": [
    "# rollout pipeline for wm model\n",
    "use_wm = True\n",
    "# use_wm = False\n",
    "# wm_mode = 'model' # 'env'\n",
    "# wm_mode = 'env' # 'model'\n",
    "wm_mode = 'model' # 'model'\n",
    "cot_mode = 'pred' # 'always', 'never'\n",
    "# cot_mode = 'always' # 'always', 'never'\n",
    "# cot_mode = 'never' # 'always', 'never'\n",
    "# cot_mode = 'always' # 'always', 'never'\n",
    "\n",
    "\n",
    "wm_init_collision_cnt = 0 # initial action has collision\n",
    "model_wm_cnt = 0 # model wm used\n",
    "model_rewind_cnt = 0 # model decide to rewind\n",
    "model_rewind_collision_cnt = 0 # model rewind has collision\n",
    "wm_init_collision_model_rewind_cnt = 0 # model collision after rewind\n",
    "\n",
    "env = gymnasium.make(\"highway-fast-v0\", render_mode='rgb_array', config={\"lanes_count\": 5})\n",
    "curr_obs, _ = env.reset()\n",
    "ego_lane_id = get_ego_lane_id(curr_obs)\n",
    "\n",
    "sampled_path_info = random.choice(goal_spec_dataset[ego_lane_id])\n",
    "\n",
    "goal_spec = sampled_path_info['goal_spec']\n",
    "hop_lane_ids = sampled_path_info['hop_lane_ids']\n",
    "\n",
    "start_id = hop_lane_ids[0]\n",
    "goal_id = hop_lane_ids[-1]\n",
    "\n",
    "curr_obs = torch.tensor(curr_obs, dtype=torch.float32)\n",
    "\n",
    "# max_rollout_length = 30\n",
    "max_rollout_length = 30\n",
    "\n",
    "ego_lane_ids = [start_id]\n",
    "actions = []\n",
    "model_failed = False\n",
    "rollout_collision = False\n",
    "\n",
    "past_input_str = goal_spec\n",
    "\n",
    "print(goal_spec)\n",
    "\n",
    "past_key_value = DynamicCache()\n",
    "past_input_embeds = model.llm_backbone.get_input_embeddings()(model.llm_tokenizer(past_input_str, return_tensors='pt').input_ids.to(curr_obs.device))\n",
    "\n",
    "generate_cfg = {'max_new_tokens': 100, 'do_sample': False}\n",
    "\n",
    "for _ in range(max_rollout_length):\n",
    "  # step 1: obtain initial action prediction\n",
    "  init_act_str, init_act_embeddings = model.init_action_inference(past_input_embeds, past_input_str, curr_obs, generate_cfg)\n",
    "  \n",
    "  print('\\tinit_act_str:', init_act_str)\n",
    "\n",
    "  if '<EndOfRollout>' in init_act_str:\n",
    "    print('\\tmodel called end of rollout!')\n",
    "    break\n",
    "\n",
    "  if '<Act_' not in init_act_str:\n",
    "    print('\\tno action token in the initial action inference string!')\n",
    "    model_failed = True\n",
    "    break\n",
    "\n",
    "  init_act_index = init_act_str.index('<Act_')\n",
    "  init_act_id = int(init_act_str[init_act_index+5:init_act_index+6])\n",
    "\n",
    "  past_input_str = past_input_str + init_act_str\n",
    "  past_input_embeds = torch.cat([past_input_embeds, init_act_embeddings], dim=1)\n",
    "\n",
    "  # step 2: obtain cot start token, decide whether to use cot or not\n",
    "  cot_token_str, cot_token_embeddings = model.cot_start_inference(past_input_embeds, past_input_str, cot_mode, use_wm)\n",
    "  \n",
    "  if len(cot_token_str) > 0:\n",
    "    past_input_str = past_input_str + cot_token_str\n",
    "    past_input_embeds = torch.cat([past_input_embeds, cot_token_embeddings], dim=1)\n",
    "\n",
    "  print('\\tcot_token_str:', cot_token_str)\n",
    "\n",
    "  if '<COMMIT>' in cot_token_str:\n",
    "    final_act_id = init_act_id\n",
    "  else:\n",
    "    # step 3: obtain world model prediction\n",
    "    if \"<BWM>\" in cot_token_str and use_wm:\n",
    "      model_wm_cnt += 1\n",
    "      if wm_mode == 'model':\n",
    "        wm_str, wm_embeddings = model.cot_append_wm_embeddings(past_input_embeds, past_input_str, None)\n",
    "      elif wm_mode == 'env':\n",
    "        wm_obs, wm_has_collision = get_wm_obs_from_env(env, init_act_id)\n",
    "        wm_obs = torch.tensor(wm_obs, dtype=torch.float32).to(curr_obs.device)\n",
    "        wm_str, wm_embeddings = model.cot_append_wm_embeddings(past_input_embeds, past_input_str, wm_obs)\n",
    "      \n",
    "      past_input_str = past_input_str + wm_str\n",
    "      past_input_embeds = torch.cat([past_input_embeds, wm_embeddings], dim=1)\n",
    "    \n",
    "    # step 4: obtain cot commit token\n",
    "    commit_str, commit_embeddings = model.cot_commit_inference(past_input_embeds, past_input_str, generate_cfg)\n",
    "    past_input_str = past_input_str + commit_str\n",
    "    past_input_embeds = torch.cat([past_input_embeds, commit_embeddings], dim=1)\n",
    "\n",
    "    print('\\tcommit_str:', commit_str)\n",
    "\n",
    "    _, wm_init_collision = get_wm_obs_from_env(env, init_act_id)\n",
    "    wm_init_collision_cnt += int(wm_init_collision)\n",
    "\n",
    "    if '<COMMIT>' not in commit_str:\n",
    "      print('\\tcot commit token is not <COMMIT>!')\n",
    "      model_failed = True\n",
    "      break\n",
    "    elif '<BACKSPACE>' in commit_str and '<Act_' in commit_str:\n",
    "      # rewind and update action\n",
    "      print('\\trewind and update action!')\n",
    "      model_rewind_cnt += 1\n",
    "      final_act_id = int(commit_str[commit_str.index('<Act_')+5:commit_str.index('<Act_')+6])\n",
    "      \n",
    "      _, wm_final_collision = get_wm_obs_from_env(env, final_act_id)\n",
    "      wm_init_collision_model_rewind_cnt += int(wm_init_collision)\n",
    "      model_rewind_collision_cnt += int(wm_final_collision)\n",
    "    else:\n",
    "      print('\\tsafe, continue to use the initial action!')\n",
    "      final_act_id = init_act_id\n",
    "      \n",
    "  # step 5: take action\n",
    "  obs, reward, has_collision, truncated, info = env.step(final_act_id)\n",
    "  ego_lane_id = get_ego_lane_id(obs)\n",
    "  \n",
    "  print(f'step: {len(actions)}, action: {final_act_id}, ego_lane_id: {ego_lane_id}')\n",
    "\n",
    "  actions.append(final_act_id)\n",
    "  ego_lane_ids.append(ego_lane_id)\n",
    "\n",
    "  curr_obs = torch.tensor(obs, dtype=torch.float32)\n",
    "\n",
    "  if truncated:\n",
    "      print('rollout finished!')\n",
    "      break\n",
    "\n",
    "  if has_collision:\n",
    "      rollout_collision = True\n",
    "      print('rollout collision!')\n",
    "      break\n",
    "\n",
    "cot_stats = {}\n",
    "\n",
    "cot_stats['collision_detect_recall'] = (wm_init_collision_model_rewind_cnt / wm_init_collision_cnt) if wm_init_collision_cnt > 0 else None\n",
    "cot_stats['rewind_precision'] = (wm_init_collision_model_rewind_cnt / model_rewind_cnt) if model_rewind_cnt > 0 else None\n",
    "cot_stats['rewind_collision_avoid_rate'] = 1 - (model_rewind_collision_cnt / model_rewind_cnt) if model_rewind_cnt > 0 else None\n",
    "cot_stats['model_rewind_ratio'] = (model_rewind_cnt / model_wm_cnt) if model_wm_cnt > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'collision_detect_recall': None,\n",
       " 'rewind_precision': None,\n",
       " 'rewind_collision_avoid_rate': None,\n",
       " 'model_rewind_ratio': 0.0}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rollout_one_episode(model, goal_spec_dataset, cot_inference_mode: str):\n",
    "    env = gymnasium.make(\"highway-fast-v0\", render_mode='rgb_array', config={\"lanes_count\": 5})\n",
    "    curr_obs, _ = env.reset()\n",
    "    ego_lane_id = get_ego_lane_id(curr_obs)\n",
    "\n",
    "    sampled_path_info = random.choice(goal_spec_dataset[ego_lane_id])\n",
    "\n",
    "    goal_spec = sampled_path_info['goal_spec']\n",
    "    hop_lane_ids = sampled_path_info['hop_lane_ids']\n",
    "\n",
    "    start_id = hop_lane_ids[0]\n",
    "    goal_id = hop_lane_ids[-1]\n",
    "\n",
    "    curr_obs = torch.tensor(curr_obs, dtype=torch.float32)\n",
    "\n",
    "    max_rollout_length = 30\n",
    "\n",
    "    ego_lane_ids = [start_id]\n",
    "    actions = []\n",
    "    model_failed = False\n",
    "    rollout_collision = False\n",
    "\n",
    "    past_input_str = goal_spec\n",
    "    past_key_value = DynamicCache()\n",
    "    past_input_embeds = model.llm_backbone.get_input_embeddings()(model.llm_tokenizer(past_input_str, return_tensors='pt').input_ids.to(curr_obs.device))\n",
    "\n",
    "    generate_cfg = {'max_new_tokens': 100, 'do_sample': False}\n",
    "\n",
    "    # print(past_input_str)\n",
    "\n",
    "    for _ in range(max_rollout_length):\n",
    "        update_str, update_embeddings = model.inference_step(past_input_embeds, past_input_str, past_key_value, curr_obs, cot_inference_mode, generate_cfg)\n",
    "        # print(update_str)\n",
    "\n",
    "        past_input_str = past_input_str + update_str\n",
    "        \n",
    "        if past_input_embeds is None:\n",
    "            past_input_embeds = update_embeddings\n",
    "        else:\n",
    "            past_input_embeds = torch.cat([past_input_embeds, update_embeddings], dim=1)\n",
    "\n",
    "        if '<EndOfRollout>' in update_str:\n",
    "            print('model called end of rollout!')\n",
    "            break\n",
    "\n",
    "        if '<Act_' not in update_str:\n",
    "            print('no action token in the update string!')\n",
    "            model_failed = True\n",
    "            break\n",
    "\n",
    "        act_index = update_str.index('<Act_')\n",
    "        act_id = int(update_str[act_index+5:act_index+6])\n",
    "\n",
    "\n",
    "        obs, reward, has_collision, truncated, info = env.step(act_id)\n",
    "        ego_lane_id = get_ego_lane_id(obs)\n",
    "        \n",
    "        # print(f'step: {len(actions)}, action: {act_id}, ego_lane_id: {ego_lane_id}')\n",
    "\n",
    "        actions.append(act_id)\n",
    "        ego_lane_ids.append(ego_lane_id)\n",
    "\n",
    "        curr_obs = torch.tensor(obs, dtype=torch.float32)\n",
    "\n",
    "        if truncated:\n",
    "            print('rollout finished!')\n",
    "            break\n",
    "\n",
    "        if has_collision:\n",
    "            rollout_collision = True\n",
    "            print('rollout collision!')\n",
    "            break\n",
    "\n",
    "    # remove repeating lane ids\n",
    "    ego_lane_ids = [ego_lane_ids[0]] + [ego_lane_ids[i] for i in range(1, len(ego_lane_ids)) if ego_lane_ids[i] != ego_lane_ids[i-1]]\n",
    "\n",
    "    token_count = past_input_embeds.shape[1]\n",
    "    action_count = len(actions)\n",
    "    reached_goal = (ego_lane_ids[-1] == goal_id) and not (model_failed or rollout_collision) and len(ego_lane_ids) == len(hop_lane_ids)\n",
    "    exact_match_score, subset_coverage = compute_path_score(hop_lane_ids, ego_lane_ids)\n",
    "\n",
    "    exceeded_length = max(0, len(ego_lane_ids) - len(hop_lane_ids))\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    scores = {'token_count': token_count, 'action_count': action_count, 'exact_match_score': exact_match_score, 'subset_coverage': subset_coverage, 'model_failed': model_failed, 'rollout_collision': rollout_collision, 'reached_goal': reached_goal, 'exceeded_length': exceeded_length}\n",
    "\n",
    "    return scores, past_input_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "log_dir = 'logs'\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollout collision!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:07<00:00,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollout collision!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import logging\n",
    "import os\n",
    "\n",
    "\n",
    "# cot_inference_mode = 'pred'\n",
    "# cot_inference_mode = 'start'\n",
    "cot_inference_mode = 'never'\n",
    "exp_name = f'{model_name}_{cot_inference_mode}'\n",
    "\n",
    "save_dir = '/u/shuhan/projects/vla/data/highway_env/rollout_experiment'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=os.path.join(save_dir, f'{exp_name}.log'),\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(message)s'\n",
    ")\n",
    "\n",
    "all_scores = {'token_count': [], 'action_count': [], 'exact_match_score': [], 'subset_coverage': [], 'model_failed': [], 'rollout_collision': [], 'reached_goal': [], 'exceeded_length': []}\n",
    "all_past_input_str = []\n",
    "\n",
    "rollout_count = 2\n",
    "\n",
    "\n",
    "for rollout_idx in tqdm.tqdm(range(rollout_count)):\n",
    "    scores, past_input_str = rollout_one_episode(model, goal_spec_dataset, cot_inference_mode)\n",
    "    for k, v in scores.items():\n",
    "        all_scores[k].append(v)\n",
    "    all_past_input_str.append(past_input_str)\n",
    "\n",
    "    logging.info(f'rollout {rollout_idx} done')\n",
    "\n",
    "    for k, v in all_scores.items():\n",
    "        logging.info(f'\\t {k}: {np.mean(v)}')\n",
    "\n",
    "logging.info('final results:')\n",
    "for k, v in all_scores.items():\n",
    "    logging.info(f'\\t {k}: {np.mean(v)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vla_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
