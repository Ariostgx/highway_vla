{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/u/shuhan/projects/vla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.vlas.cont_obs_token_action_cot_unified_token import ContObsTokenActionCOTVLAUnifiedToken\n",
    "from src.auto_labeling.highway_env.lane_change import LaneChangeTaskSpec\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "llm_model = 'HuggingFaceTB/SmolLM2-135M-Instruct'\n",
    "\n",
    "llm_backbone = AutoModelForCausalLM.from_pretrained(llm_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model)\n",
    "\n",
    "loss_weight = {\"action\": 1.0, \"obs\": 0.0, 'reconst': 1.0, \"cot\": 1.0, \"separator\": 1.0, \"rollout_stop\": 1.0}\n",
    "cot_mode = 'start'\n",
    "cot_cfg = {'lanes_count': 5, 'max_hop': 4, 'cot_index_mode': 'both'}\n",
    "\n",
    "if llm_model == 'gpt2':\n",
    "  hidden_dim = 768\n",
    "elif llm_model == 'HuggingFaceTB/SmolLM2-135M-Instruct':\n",
    "  hidden_dim = 576\n",
    "else:\n",
    "  raise ValueError(f'Unknown LLM model: {llm_model}')\n",
    "\n",
    "obs_dim = 25\n",
    "num_actions = 5\n",
    "mlp_layers = 2\n",
    "\n",
    "task_spec_func = LaneChangeTaskSpec\n",
    "\n",
    "model = ContObsTokenActionCOTVLAUnifiedToken(llm_backbone, tokenizer, task_spec_func, obs_dim, num_actions, hidden_dim, mlp_layers, loss_weight, cot_mode, cot_cfg, max_obs_len=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "ckpt = os.path.expanduser('~/results/vla/quick_run_cot_unified/start_cot_smolLM/lightning_logs/version_0/checkpoints/test_model.ckpt')\n",
    "\n",
    "lg_ckpt = torch.load(ckpt, map_location='cpu', weights_only=True)['state_dict']\n",
    "ori_ckpt = {}\n",
    "for k, v in lg_ckpt.items():\n",
    "    if k.startswith('vla.'):\n",
    "        ori_ckpt[k[4:]] = v\n",
    "\n",
    "model.load_state_dict(ori_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.environments.highway_env.dataset import HighwayDataset, collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_folder = '/storage/Datasets/highway_env/highway_fast_v0_dqn_meta_action_5_lanes/rollouts_train'\n",
    "dataset = HighwayDataset(data_folder)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 5, 5]) torch.Size([1, 20]) torch.Size([1, 20])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "  break\n",
    "obs, act, valid_mask = batch\n",
    "print(obs.shape, act.shape, valid_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_dict, batch_input_embeds, batch_label_ids, batch_input_ids, llm_output = model.forward(obs, act, valid_mask)\n",
    "padding_mask = batch_label_ids[0] == -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = model.llm_tokenizer.decode(batch_input_ids[0], skip_special_tokens=False)\n",
    "eoo_token_id = model.llm_tokenizer('<EOO>')['input_ids'][0]\n",
    "eot_token_id = model.llm_tokenizer('<EOT>')['input_ids'][0]\n",
    "eoa_token_id = model.llm_tokenizer('<EOA>')['input_ids'][0]\n",
    "init_context_len = batch_input_ids[0].cpu().tolist().index(eoo_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOT>Now at Lane 2. Follow Lane 1 -> Lane 2 -> Lane 3 -> Lane 4. Next is Lane 1. Action: turn left.<EOT><BOA><Act_3><EOA><|endoftext|><|endoftext|><|endoftext|><BOA><Act_0><EOA><|endoftext|><|endoftext|><|endoftext|><BOA><Act_3><EOA><|endoftext|><|endoftext|><|endoftext|><BOA><Act_2><EOA><|endoftext|><|endoftext|><|endoftext|><BOA><Act_1><EOA><|endoftext|><|endoftext|><|endoftext|><BOA><Act_1><EOA><|endoftext|><|endoftext|><|endoftext|><BOA><Act_2><EOA><|endoftext|><|endoftext|><|endoftext|><BOA><Act_2><EOA><|endoftext|><|endoftext|><|endoftext|><EndOfRollout>\n"
     ]
    }
   ],
   "source": [
    "batch_label_ids[0][padding_mask] = tokenizer.pad_token_id\n",
    "\n",
    "gt_str = model.llm_tokenizer.decode(batch_label_ids[0][init_context_len:], skip_special_tokens=False)\n",
    "print(gt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOT>Now at Lane 2. Follow Lane 1 -> Lane 2 -> Lane 3 -> Lane 4. Next is Lane 1. Action: turn left.<EOT><BOA><Act_3><EOA><|endoftext|><|endoftext|><|endoftext|><BOA><Act_0><EOA><|endoftext|><|endoftext|><|endoftext|><BOA><Act_3><EOA><|endoftext|><|endoftext|><|endoftext|><BOA><Act_2><EOA><|endoftext|><|endoftext|><|endoftext|><BOA><Act_1><EOA><|endoftext|><|endoftext|><|endoftext|><BOA><Act_1><EOA><|endoftext|><|endoftext|><|endoftext|><BOA><Act_2><EOA><|endoftext|><|endoftext|><|endoftext|><BOA><Act_2><EOA><|endoftext|><|endoftext|><|endoftext|><EndOfRollout>\n"
     ]
    }
   ],
   "source": [
    "model_pred_ids = torch.argmax(llm_output.logits, axis=-1)\n",
    "model_pred_ids[0][padding_mask] = tokenizer.pad_token_id\n",
    "model_pred_str = model.llm_tokenizer.decode(model_pred_ids[0][init_context_len:], skip_special_tokens=False)\n",
    "\n",
    "print(model_pred_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Goal is to reach Lane 4. Need to go through path Lane 2 -> Lane 1 -> Lane 2 -> Lane 3 -> Lane 4.<BOO><Obs_0><EOO>'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.llm_tokenizer.decode(batch_input_ids[0][:init_context_len+1], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOT>Now at Lane 2. Follow Lane 1 -> Lane 2 -> Lane 3 -> Lane 4. Next is Lane 1. Action: turn left.<EOT><BOA><Act_3><EOA>\n"
     ]
    }
   ],
   "source": [
    "context_input_embeds = batch_input_embeds[:, :init_context_len+1]\n",
    "\n",
    "rollout_output = model.llm_backbone.generate(inputs_embeds=context_input_embeds, max_new_tokens=100, do_sample=False, eos_token_id=eoa_token_id)\n",
    "rollout_output_str = model.llm_tokenizer.decode(rollout_output[0], skip_special_tokens=False)\n",
    "print(rollout_output_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vla_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
