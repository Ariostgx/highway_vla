{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/u/shuhan/projects/vla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/shuhan/anaconda3/envs/vla_hw/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.models.vlas.cont_obs_token_action_cot_unified_token import ContObsTokenActionCOTVLAUnifiedToken\n",
    "from src.auto_labeling.highway_env.lane_change import LaneChangeTaskSpec\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "llm_model = 'HuggingFaceTB/SmolLM2-135M-Instruct'\n",
    "\n",
    "llm_backbone = AutoModelForCausalLM.from_pretrained(llm_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model)\n",
    "\n",
    "loss_weight = {\"action\": 1.0, \"obs\": 0.0, 'reconst': 1.0, \"cot\": 1.0, \"separator\": 1.0, \"rollout_stop\": 1.0}\n",
    "cot_mode = 'start'\n",
    "cot_cfg = {'lanes_count': 5, 'max_hop': 4, 'cot_index_mode': 'both'}\n",
    "\n",
    "if llm_model == 'gpt2':\n",
    "  hidden_dim = 768\n",
    "elif llm_model == 'HuggingFaceTB/SmolLM2-135M-Instruct':\n",
    "  hidden_dim = 576\n",
    "else:\n",
    "  raise ValueError(f'Unknown LLM model: {llm_model}')\n",
    "\n",
    "obs_dim = 25\n",
    "num_actions = 5\n",
    "mlp_layers = 2\n",
    "\n",
    "task_spec_func = LaneChangeTaskSpec\n",
    "\n",
    "model = ContObsTokenActionCOTVLAUnifiedToken(llm_backbone, tokenizer, task_spec_func, obs_dim, num_actions, hidden_dim, mlp_layers, loss_weight, cot_mode, cot_cfg, max_obs_len=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "model_paths = {'full_cot_smolLM': '~/results/vla/quick_run_cot_unified/full_cot_smolLM/lightning_logs/version_6/checkpoints/test_model.ckpt',\n",
    "               'start_cot_smolLM': '~/results/vla/quick_run_cot_unified/start_cot_smolLM/lightning_logs/version_0/checkpoints/test_model.ckpt',\n",
    "               'never_cot_smolLM': '~/results/vla/quick_run_cot_unified/no_cot_smolLM/lightning_logs/version_1/checkpoints/test_model.ckpt'}\n",
    "\n",
    "model_name = 'full_cot_smolLM'\n",
    "\n",
    "ckpt = os.path.expanduser(model_paths[model_name])\n",
    "\n",
    "lg_ckpt = torch.load(ckpt, map_location='cpu', weights_only=True)['state_dict']\n",
    "ori_ckpt = {}\n",
    "for k, v in lg_ckpt.items():\n",
    "    if k.startswith('vla.'):\n",
    "        ori_ckpt[k[4:]] = v\n",
    "\n",
    "model.load_state_dict(ori_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "goal_spec_dataset_path = '/u/shuhan/projects/vla/data/highway_env/lane_change_goal_spec_data.pkl'\n",
    "with open(goal_spec_dataset_path, 'rb') as f:\n",
    "  goal_spec_dataset = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import gymnasium\n",
    "import highway_env\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "from transformers.cache_utils import DynamicCache\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def get_ego_lane_id(curr_obs):\n",
    "  lane_cnt = 5\n",
    "  lane_width = 1.0 / lane_cnt\n",
    "  abs_y = curr_obs[..., 2].copy()\n",
    "  abs_y[1:] += abs_y[:1]\n",
    "  abs_y += lane_width / 2\n",
    "  lane_ids = (abs_y / lane_width).astype(int)\n",
    "  ego_lane_id = lane_ids[0]\n",
    "  return ego_lane_id\n",
    "\n",
    "def compute_path_score(goal_path: list[int], ego_lane_ids: list[int]):\n",
    "  # exact match\n",
    "  exact_match_count = sum(1 for g, e in zip(goal_path, ego_lane_ids) if g == e)\n",
    "  exact_match_score = exact_match_count / len(goal_path)\n",
    "\n",
    "  # subset coverage\n",
    "  sequence_matcher = SequenceMatcher(None, goal_path, ego_lane_ids)\n",
    "  longest_match_length = sequence_matcher.find_longest_match(0, len(goal_path), 0, len(ego_lane_ids)).size\n",
    "  subset_coverage = longest_match_length / len(goal_path)\n",
    "\n",
    "  return exact_match_score, subset_coverage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rollout_one_episode(model, goal_spec_dataset, cot_inference_mode: str):\n",
    "    env = gymnasium.make(\"highway-fast-v0\", render_mode='rgb_array', config={\"lanes_count\": 5})\n",
    "    curr_obs, _ = env.reset()\n",
    "    ego_lane_id = get_ego_lane_id(curr_obs)\n",
    "\n",
    "    sampled_path_info = random.choice(goal_spec_dataset[ego_lane_id])\n",
    "\n",
    "    goal_spec = sampled_path_info['goal_spec']\n",
    "    hop_lane_ids = sampled_path_info['hop_lane_ids']\n",
    "\n",
    "    start_id = hop_lane_ids[0]\n",
    "    goal_id = hop_lane_ids[-1]\n",
    "\n",
    "    curr_obs = torch.tensor(curr_obs, dtype=torch.float32)\n",
    "\n",
    "    max_rollout_length = 30\n",
    "\n",
    "    ego_lane_ids = [start_id]\n",
    "    actions = []\n",
    "    model_failed = False\n",
    "    rollout_collision = False\n",
    "\n",
    "    past_input_str = goal_spec\n",
    "    past_key_value = DynamicCache()\n",
    "    past_input_embeds = model.llm_backbone.get_input_embeddings()(model.llm_tokenizer(past_input_str, return_tensors='pt').input_ids.to(curr_obs.device))\n",
    "\n",
    "    generate_cfg = {'max_new_tokens': 100, 'do_sample': False}\n",
    "\n",
    "    # print(past_input_str)\n",
    "\n",
    "    for _ in range(max_rollout_length):\n",
    "        update_str, update_embeddings = model.inference_step(past_input_embeds, past_input_str, past_key_value, curr_obs, cot_inference_mode, generate_cfg)\n",
    "        # print(update_str)\n",
    "\n",
    "        past_input_str = past_input_str + update_str\n",
    "        \n",
    "        if past_input_embeds is None:\n",
    "            past_input_embeds = update_embeddings\n",
    "        else:\n",
    "            past_input_embeds = torch.cat([past_input_embeds, update_embeddings], dim=1)\n",
    "\n",
    "        if '<EndOfRollout>' in update_str:\n",
    "            print('model called end of rollout!')\n",
    "            break\n",
    "\n",
    "        if '<Act_' not in update_str:\n",
    "            print('no action token in the update string!')\n",
    "            model_failed = True\n",
    "            break\n",
    "\n",
    "        act_index = update_str.index('<Act_')\n",
    "        act_id = int(update_str[act_index+5:act_index+6])\n",
    "\n",
    "\n",
    "        obs, reward, has_collision, truncated, info = env.step(act_id)\n",
    "        ego_lane_id = get_ego_lane_id(obs)\n",
    "        \n",
    "        # print(f'step: {len(actions)}, action: {act_id}, ego_lane_id: {ego_lane_id}')\n",
    "\n",
    "        actions.append(act_id)\n",
    "        ego_lane_ids.append(ego_lane_id)\n",
    "\n",
    "        curr_obs = torch.tensor(obs, dtype=torch.float32)\n",
    "\n",
    "        if truncated:\n",
    "            print('rollout finished!')\n",
    "            break\n",
    "\n",
    "        if has_collision:\n",
    "            rollout_collision = True\n",
    "            print('rollout collision!')\n",
    "            break\n",
    "\n",
    "    # remove repeating lane ids\n",
    "    ego_lane_ids = [ego_lane_ids[0]] + [ego_lane_ids[i] for i in range(1, len(ego_lane_ids)) if ego_lane_ids[i] != ego_lane_ids[i-1]]\n",
    "\n",
    "    token_count = past_input_embeds.shape[1]\n",
    "    action_count = len(actions)\n",
    "    reached_goal = (ego_lane_ids[-1] == goal_id) and not (model_failed or rollout_collision) and len(ego_lane_ids) == len(hop_lane_ids)\n",
    "    exact_match_score, subset_coverage = compute_path_score(hop_lane_ids, ego_lane_ids)\n",
    "\n",
    "    exceeded_length = max(0, len(ego_lane_ids) - len(hop_lane_ids))\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    scores = {'token_count': token_count, 'action_count': action_count, 'exact_match_score': exact_match_score, 'subset_coverage': subset_coverage, 'model_failed': model_failed, 'rollout_collision': rollout_collision, 'reached_goal': reached_goal, 'exceeded_length': exceeded_length}\n",
    "\n",
    "    return scores, past_input_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "log_dir = 'logs'\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollout collision!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:07<00:00,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollout collision!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import logging\n",
    "import os\n",
    "\n",
    "\n",
    "# cot_inference_mode = 'pred'\n",
    "# cot_inference_mode = 'start'\n",
    "cot_inference_mode = 'never'\n",
    "exp_name = f'{model_name}_{cot_inference_mode}'\n",
    "\n",
    "save_dir = '/u/shuhan/projects/vla/data/highway_env/rollout_experiment'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=os.path.join(save_dir, f'{exp_name}.log'),\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(message)s'\n",
    ")\n",
    "\n",
    "all_scores = {'token_count': [], 'action_count': [], 'exact_match_score': [], 'subset_coverage': [], 'model_failed': [], 'rollout_collision': [], 'reached_goal': [], 'exceeded_length': []}\n",
    "all_past_input_str = []\n",
    "\n",
    "rollout_count = 2\n",
    "\n",
    "\n",
    "for rollout_idx in tqdm.tqdm(range(rollout_count)):\n",
    "    scores, past_input_str = rollout_one_episode(model, goal_spec_dataset, cot_inference_mode)\n",
    "    for k, v in scores.items():\n",
    "        all_scores[k].append(v)\n",
    "    all_past_input_str.append(past_input_str)\n",
    "\n",
    "    logging.info(f'rollout {rollout_idx} done')\n",
    "\n",
    "    for k, v in all_scores.items():\n",
    "        logging.info(f'\\t {k}: {np.mean(v)}')\n",
    "\n",
    "logging.info('final results:')\n",
    "for k, v in all_scores.items():\n",
    "    logging.info(f'\\t {k}: {np.mean(v)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vla_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
